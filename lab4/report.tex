\input{../template.tex}

% Dokumentinformationen
\newcommand{\SUBJECT}{Report}
\newcommand{\TITLE}{Cloud Infrastructre Lab 4}

\input{../front.tex}

%  03.11.2016, 23:55, as PDF to beat.stettler@ins.hsr.ch. 

% Describe how Qemu KVM and Docker work (technical explanation). Also make sure you highlight the 
% differences, pro’s and con’s. 

% Setup and configuration of the Qemu-KVM environment (with explanations) 

% Qemu network configuration 

% A short manual of how to get the ELK stack up and running in Docker 

% Docker network configuration 

% Docker Compose file for the ELK stack 

% Qemu-KVM and Docker networking configuration files/scripts 

\section{Grundlegendes}
\subsection{Terminologie}
\begin{description}
	\item[Host System] \hfill \\
	Beherbergt eine Virtualisierungslösung und stellt Funktionen zur Verfügung damit ein Gastsystem laufen kann.
	\item[Guest System] \hfill \\
	Läuft virtuell innerhalb des Host Systems. Befehle werden durch eine Virtualisierungslösung an die Hardware des Hosts weitergeleitet. 
	\item[Container, VDI: Virtual Disk Image] \hfill \\
	 Virtuelle Festplatte des Gastsystems. Es gibt statische und dynamische Container.
\end{description}

\subsection{KVM: Kernel-based Virtual Machine}
KVM ist eine Virtualisierungslösung für Linux, die Gebrauch von Virtualisierungstechniken aktueller x86 Prozessoren macht. Um KVM nutzen zu können muss der Prozessor des Hostsystems Hardwarevirtualisierung unterstützen. KVM an sich stellt die direkte Schnittstelle zum Linux-Kernel zur Verfügung, als Virtualisierungsumgebung kommt QEMU zum Einsatz.

\subsection{QEMU}
QEMU ist ein quelloffener Emulator und Virtualisierer. QEMU kommuniziert direkt mit dem Kernel, so dass das Gastsystem annähernd mit der Geschwindigkeit des Hosts läuft. 

\subsection{Docker}
Docker ist im Gegensatz zu KVM keine virtuelle Maschiene sondern basiert auf Linux Container (LXC). Ein LXC ist eine vom Betriebssystem bereitgestellte virtuelle Umgebung zur isolierten Ausführung von Prozessen. Docker packt eine Anwendung einschliesslich ihrer Abhängikeiten in einen Container. Das Betriebssystem des Container muss einzig den gleichen Kernel wie das Hostsystem verwenden. In Docker lassen sich Ketten von bis zu 127 Images erstellen, die dann von Docker zur Ausführung in einen Container zusammengafasst werden. Docker wird verwendet um Prozess isoliert voneinander auszuführen. 


\section{Qemu KVM}
\subsection{Grundlegendes}

\subsection{Beschreibung}
\paragraph{Vorteile}
\begin{itemize}
	\item Ein Vorteil von KVM ist, dass die Gastsysteme fast mit nativer Geschwindigkeit laufen, d.h. das Gastsystem reagiert nahezu so schnell wie ein natives System. 
\end{itemize}
\paragraph{Nachteile}
\begin{itemize}
	\item Hoher Bedarf an Festplatten und Arbeitsspeicher und langwieriger Ladevorgang beim Starten der virtuellen Maschienen
\end{itemize}

\subsection{Setup}
\subsubsection{Abhängigkeitn}
\begin{enumerate}
	\item \lstinline|sudo dnf install @virtualization docker-io libvirt-docs|
	\item \lstinline|sudo service libvirtd start|
\end{enumerate}

\subsubsection{Vorraussetzung}
\paragraph{Hardwarevirtualisierung} \hfill \\
Damit KVM genutzt werden kann, muss die CPU Hardwarevirtualisierung unterstützen. Dies kann mit folgendem Befehl herausgefunden werden.
\begin{lstlisting}[language=bash]
# Eintrag VMX oder SVM sollten hervorgehoben werden
egrep '(vmx|svm)' /proc/cpuinfo
\end{lstlisting}

Die nötigen Kernelmodule werden grundsätzlich automatisch geladen. Sollte dies nicht der Fall sein, können sie mit folgendem Befehl geladen werden.
\begin{lstlisting}[language=bash]
lsmod | grep kvm # Sollte kvm und kvm_intel ausgeben 

# manuell laden
sudo modprobe kvm
sudo modprobe kvm_intel
\end{lstlisting}

\paragraph{Usergroups} \hfill \\
Der aktuelle User sollte noch den Gruppen \lstinline|libvirt| und \lstinline|kvm| hinzugefügt werden.
\begin{lstlisting}[language=bash]
sudo usermod -aG libvirt, kvm $USER
\end{lstlisting}





\subsubsection{Image herunterladen}
\begin{enumerate}
	\item Cirros Festplatten Image herunterladen: \url{http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img}
	\item Festplatten Image nach \lstinline|/var/lib/libvirt/images/| verschieben
	\item Für jede virtuelle Maschiene eine Kopie des Festplatten Image anlegen
\end{enumerate}

\subsubsection{Virt-Image}
Um eine neue virtuelle Maschiene anzulegen, muss eine XML-Datei unter \lstinline|/etc/libvirt/qemu| erstellt werden. Die Datei beschreibt wie die VM auszusehen hat. 

\begin{lstlisting}[language=XML]
 TODO copy xml vm1, vm2, vm3 from /etc/libvirt/qemu
\end{lstlisting}

\subsubsection{Virt-Install}

\subsubsection{Virt-Clone}
Die weiteren WM's wurden geklont und gemäss Ihren Anforderungen angepasst.
\begin{lstlisting}[language=bash]

\end{lstlisting}


\subsection{Network Configuration}
% TODO Remove sources
% http://wiki.qemu.org/Documentation/Networking#Network_backend_types
% http://wiki.libvirt.org/page/Networking#Debian.2FUbuntu_Bridging


\subsubsection{Grundlegend}
Für jedes virtuelle Netzwerk legt libvirt eine virtuelle Bridge an. Diese können auf dem Host mit \lstinline|brctl show| angezeigt werden. Zudem wird ein virtuelles Interface im zugewiesenen Adressraum (default: 192.168.122.0/24) erstellt, das per NAT mit der physischen Netzwerkkarte verbunden ist. Damit jeder virtuelle Maschine eine gültige IP Adresse kriegt, wird auf dem Host Interface ein DHCP Server (dnsmasq) eingerichtet. Mit dieser Konfiguration kann jede virtuelle Maschine ins Internet, hat jedoch keine Konnektivität zu den anderen VM's. 

\begin{description}
	\item[/var/lib/libvirt/dnsmasq] Die DHCP Konfigurations-Files 
	\item[/etc/libvirt/qemu/networks] Netzwerk Konfigurations-Files
\end{description}




\subsubsection{Host einrichten}
\begin{lstlisting}[language=bash]
virsh net-define /usr/share/libvirt/networks/default.xml
virsh net-autostart default
virsh net-start default
virsh net-edit <network-name>
\end{lstlisting}


\lstinline|/etc/libvirt/qemu/networks|

\subsubsection{Bridge Erstellen}
\begin{lstlisting}[language=xml]
<network>
	<name>VM1_VM2</name>
	<uuid>b7aca73a-21b9-43af-8c91-0af4f95bd29b</uuid>
	<bridge name='virbr1' stp='on' delay='0'/>
	<mac address='52:54:00:1e:b6:ae'/>
	<domain name='VM1_VM2'/>
	<ip address='192.168.100.1' netmask='255.255.255.0'>
	<dhcp>
	<range start='192.168.100.128' end='192.168.100.254'/>
	</dhcp>
	</ip>
</network>
\end{lstlisting}







\section{Docker}
\subsection{Grundlegendes}

\subsection{Docker IO}
\begin{lstlisting}[language=bash]
# docker container suchen
docker sarch <package-name>

# docker container herunterladen
docker pull <package-name>

# Image veroeffentlichen
docker push <image name>

# docker container starten
docker run <package-name> <app to execute>

# Aktuell ausgefuerten Container anzeigen
docker ps

# Liste alle lokal vorliegenden Images
docker images

# Image entfernen
docker rmi <image>

# Container entfernen
docker rm <container>
\end{lstlisting}


\subsection{Beschreibung}
\paragraph{Vorteile}
\begin{itemize}
	\item Äusserts sparsamer Umgang mit Ressourcen und eine kurze Startzeit	
	\item Mit Hilfe von Vagrant äusserts einfach einen Docker Container zu installieren
	\item Austausch von Images fällt durch den Gebrauch von öffentlichen Registries leicht.
\end{itemize}
\paragraph{Nachteile}
\begin{itemize}
	\item Da die Container auf den Linux Kernel zugreifen, ist es nicht möglich Windows Anwendungen in einem Docker Container auszuführen.
	\item Einschränkung auf 64Bit basiertes Linux oder Mac OSX (%TODO immer noch=?
\end{itemize}

\subsection{ELK Stack Setup (Elasticseach, Logstash, Kibana)}
\subsubsection{Vorraussetzungen}
\paragraph{SELinux} \hfill \\
Da wir mit einem Fedora arbeiten, müssen vorgän
\begin{lstlisting}[language=bash]
chcon -R system_u:object_r:admin_home_t:s0 docker-elk
\end{lstlisting}



\subsection{Network Configuration}

\subsection{Docker Compose File ELK Stack}




\section{Vergleich der Technologien}


\input{appendix.tex}
