\input{../template.tex}

% Dokumentinformationen
\newcommand{\SUBJECT}{Report}
\newcommand{\TITLE}{Cloud Infrastructre Lab 4}

\input{../front.tex}

%  03.11.2016, 23:55, as PDF to beat.stettler@ins.hsr.ch. 

% Describe how Qemu KVM and Docker work (technical explanation). Also make sure you highlight the 
% differences, pro’s and con’s. 

% Setup and configuration of the Qemu-KVM environment (with explanations) 

% Qemu network configuration 

% A short manual of how to get the ELK stack up and running in Docker 

% Docker network configuration 

% Docker Compose file for the ELK stack 

% Qemu-KVM and Docker networking configuration files/scripts 

\section{Grundlegendes}
\subsection{Terminologie}
\begin{description}
	\item[Host System] \hfill \\
	Beherbergt eine Virtualisierungslösung und stellt Funktionen zur Verfügung damit ein Gastsystem laufen kann.
	\item[Guest System] \hfill \\
	Läuft virtuell innerhalb des Host Systems. Befehle werden durch eine Virtualisierungslösung an die Hardware des Hosts weitergeleitet. 
	\item[Container, VDI: Virtual Disk Image] \hfill \\
	 Virtuelle Festplatte des Gastsystems. Es gibt statische und dynamische Container.
\end{description}

\subsection{KVM: Kernel-based Virtual Machine}
KVM ist eine Virtualisierungslösung für Linux, die Gebrauch von Virtualisierungstechniken aktueller Prozessorarchitekturen macht. Um KVM nutzen zu können muss der Prozessor des Hostsystems Hardwarevirtualisierung unterstützen (was bei den meisten neueren Intel und AMD Prozessoren der Fall ist). KVM an sich stellt die direkte Schnittstelle zum Linux-Kernel zur Verfügung, als Virtualisierungsumgebung kommt QEMU zum Einsatz.

\subsection{QEMU}
QEMU ist ein quelloffener Emulator und Virtualisierer. QEMU kommuniziert direkt via KVM mit dem Kernel und der CPU, um so dass das Gastsystem möglichst nahe and der Hardware laufen zu lassen. Eine komplette Emulation (Vollvirtualisierung) ist mit QEMU ebenfalls möglich, führt jedoch zu grossen Performanceeinbussen.

\subsection{Docker}
Docker ist im Gegensatz zu KVM keine Lösung für virtuelle Maschinen (und damit unabhängige Betriebssysteme mit eigenem CPU-Scheduling etc.) sondern basiert auf Linux Container (LXC). Ein LXC ist eine vom Kernel bereitgestellte virtuelle Umgebung zur isolierten Ausführung von Prozessen.

Docker ermöglicht neben der Steuerung von isolierten Applikationsausführung in LXC die Konfiguration von Netzwerkeinstellungen bzw. Portfreigabe ein komplett isoliertes Dateisystem pro Applikation (sogenannte Images). Damit ist es möglich, Systemunabhängig immer die gleiche Plattform zur Ausführung zu paketieren und weiter zu verteilen. Von Docker erstellte Images werden üblicherweise mit einem Dateisystem erstellt, welches Snapshots erlaubt (z.B. AUFS, UnionFS oder BTRFS).

Zur Erstellung von eigenen Images, auf deren Basis eine Applikation ausgeführt wird, können mit einem \lstinline[]|Dockerfile| komplette ''Bauanleitungen'' erstellt werden. Im \lstinline[]|Dockerfile| sind die Eigenschaften des neuen Container und Images sowie darauf auszuführende Kommandos zur Bereitstellung der Umgebung hinterlegt.

So gebaute Images (oft in diesem Zusammenhang auch einfach als Container bezeichnet) können über eine Online-Plattform verteilt werden. Die Firma Docker Inc. stellt zu diesem Zweck die öffentliche Plattform \emph{DockerHub} unter https://hub.docker.com/ zur Verfügung.

Beim Bauen eines Containers wird üblicherweise auf die Basis eines bestehenden Containers auf der DockerHub-Plattform zurückgegriffen. So gibt es dort zum Beispiel Images, welche die Dateisystemstruktur und Bibliotheken eines minimalen Ubuntu-Systems oder sogar einer Umgebung für  wie Ruby on Rails zur Verfügung stellen.

\subsubsection{Docker Compose}

Docker Compose ist ein ergänzendes Programm zu Docker, welches die Provisionierung und Verknüpfung von mehreren Docker-Containern erlaubt. Der Aufbau/Start der Container wird mittels dem Kommando \lstinline|docker-compose| gesteuert; dies liest die \lstinline|docker-compose.yml|-Datei ein, in welcher weitergehende Anweisung für die Konfiguration der Container definiert sind.
%TODO Michi: Fehlt hier noch etwas?

\subsubsection{Docker Swarm}
Docker Swarm ist ein Orchestrierungs-Werkzeug für den Betrieb von Docker-Clustern (oder auch einzelnen Docker Hosts).
%TODO Michi: Was kann das noch mehr?.


\section{KVM / Qemu}
\subsection{Grundlegendes}

\subsection{Beschreibung}
\paragraph{Vorteile}
\begin{itemize}
	\item Ein Vorteil von KVM ist, dass die Gastsysteme fast mit nativer Geschwindigkeit laufen, d.h. das Gastsystem reagiert nahezu so schnell wie ein natives System. 
\end{itemize}
\paragraph{Nachteile}
\begin{itemize}
	\item Hoher Bedarf an Festplatten und Arbeitsspeicher und langwieriger Ladevorgang beim Starten der virtuellen Maschienen
\end{itemize}

\subsection{Setup}
\subsubsection{Abhängigkeiten}
\begin{enumerate}
	\item \lstinline|sudo dnf install @virtualization docker-io libvirt-docs|
	\item \lstinline|sudo service libvirtd start|
\end{enumerate}

\subsubsection{Vorraussetzung}
\paragraph{Hardwarevirtualisierung} \hfill \\
Damit KVM genutzt werden kann, muss die CPU Hardwarevirtualisierung unterstützen. Dies kann mit folgendem Befehl herausgefunden werden.
\begin{lstlisting}[language=bash]
# Eintrag VMX oder SVM sollten hervorgehoben werden
egrep '(vmx|svm)' /proc/cpuinfo
\end{lstlisting}

Die nötigen Kernelmodule werden grundsätzlich automatisch geladen. Sollte dies nicht der Fall sein, können sie mit folgendem Befehl geladen werden.
\begin{lstlisting}[language=bash]
lsmod | grep kvm # Sollte kvm und kvm_intel ausgeben 

# manuell laden
sudo modprobe kvm
sudo modprobe kvm_intel
\end{lstlisting}

\paragraph{Usergroups} \hfill \\
Der aktuelle User sollte noch den Gruppen \lstinline|libvirt| und \lstinline|kvm| hinzugefügt werden.
\begin{lstlisting}[language=bash]
sudo usermod -aG libvirt, kvm $USER
\end{lstlisting}





\subsubsection{Image herunterladen}
\begin{enumerate}
	\item Cirros Festplatten Image herunterladen: \url{http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img}
	\item Festplatten Image nach \lstinline|/var/lib/libvirt/images/| verschieben
	\item Für jede virtuelle Maschiene eine Kopie des Festplatten Image anlegen
\end{enumerate}

\subsubsection{Virt-Image}
Um eine neue virtuelle Maschiene anzulegen, muss eine XML-Datei unter \lstinline|/etc/libvirt/qemu| erstellt werden. Die Datei beschreibt wie die VM auszusehen hat. 


\begin{lstlisting}[language=bash]
virsh create /etc/libvirt/qemu/VM1.xml

virsh start VM1 

virsh console VM1
\end{lstlisting}

\begin{lstlisting}[language=XML]
 TODO copy xml vm1, vm2, vm3 from /etc/libvirt/qemu
\end{lstlisting}

\subsubsection{Virt-Install}

\subsubsection{Virt-Clone}
Die weiteren WM's wurden geklont und gemäss Ihren Anforderungen angepasst.
\begin{lstlisting}[language=bash]

\end{lstlisting}


\subsection{Network Configuration}
% TODO Remove sources
% http://wiki.qemu.org/Documentation/Networking#Network_backend_types
% http://wiki.libvirt.org/page/Networking#Debian.2FUbuntu_Bridging


\subsubsection{Grundlegend}
Für jedes virtuelle Netzwerk legt libvirt eine virtuelle Bridge an. Diese können auf dem Host mit \lstinline|brctl show| angezeigt werden. Zudem wird ein virtuelles Interface im zugewiesenen Adressraum (default: 192.168.122.0/24) erstellt, das per NAT mit der physischen Netzwerkkarte verbunden ist. Damit jeder virtuelle Maschine eine gültige IP Adresse kriegt, wird auf dem Host Interface ein DHCP Server (dnsmasq) eingerichtet. Mit dieser Konfiguration kann jede virtuelle Maschine ins Internet, hat jedoch keine Konnektivität zu den anderen VM's. 

\begin{description}
	\item[/var/lib/libvirt/dnsmasq] Die DHCP Konfigurations-Files 
	\item[/etc/libvirt/qemu/networks] Netzwerk Konfigurations-Files
\end{description}




\subsubsection{Host einrichten}
\begin{lstlisting}[language=bash]
virsh net-define /usr/share/libvirt/networks/default.xml
virsh net-autostart default
virsh net-start default
virsh net-edit <network-name>
\end{lstlisting}


\lstinline|/etc/libvirt/qemu/networks|

\subsubsection{Bridge Erstellen}
\begin{lstlisting}[language=xml]
<network>
	<name>VM1_VM2</name>
	<uuid>b7aca73a-21b9-43af-8c91-0af4f95bd29b</uuid>
	<bridge name='virbr1' stp='on' delay='0'/>
	<mac address='52:54:00:1e:b6:ae'/>
	<domain name='VM1_VM2'/>
	<ip address='192.168.100.1' netmask='255.255.255.0'>
	<dhcp>
	<range start='192.168.100.128' end='192.168.100.254'/>
	</dhcp>
	</ip>
</network>
\end{lstlisting}







\section{Docker}
\subsection{Grundlegendes}

\subsection{Docker IO}
\begin{lstlisting}[language=bash]
# docker container suchen
docker sarch <package-name>

# docker container herunterladen
docker pull <package-name>

# Image veroeffentlichen
docker push <image name>

# docker container starten
docker run <package-name> <app to execute>

# Aktuell ausgefuerten Container anzeigen
docker ps

# Liste alle lokal vorliegenden Images
docker images

# Image entfernen
docker rmi <image>

# Container entfernen
docker rm <container>
\end{lstlisting}


\subsection{Beschreibung}
\paragraph{Vorteile}
\begin{itemize}
	\item Äusserts sparsamer Umgang mit Ressourcen und eine kurze Startzeit	
	\item Mit Hilfe von Vagrant äusserts einfach einen Docker Container zu installieren
	\item Austausch von Images fällt durch den Gebrauch von öffentlichen Registries leicht.
\end{itemize}
\paragraph{Nachteile}
\begin{itemize}
	\item Da die Container auf den Linux Kernel zugreifen, ist es nicht möglich Windows Anwendungen in einem Docker Container auszuführen.
	\item Einschränkung auf 64Bit basiertes Linux oder Mac OSX (%TODO immer noch=?
\end{itemize}

\subsection{ELK Stack Setup (Elasticseach, Logstash, Kibana)}
\subsubsection{Vorraussetzungen}
\paragraph{SELinux} \hfill \\
Da wir mit einem Fedora arbeiten, müssen vorgän
\begin{lstlisting}[language=bash]
chcon -R system_u:object_r:admin_home_t:s0 docker-elk
\end{lstlisting}



\subsection{Network Configuration}

\subsection{Docker Compose File ELK Stack}




\section{Vergleich der Technologien}


\input{appendix.tex}
