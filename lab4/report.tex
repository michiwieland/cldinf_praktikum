\input{../template.tex}

% Dokumentinformationen
\newcommand{\SUBJECT}{Report}
\newcommand{\TITLE}{Cloud Infrastructre Lab 4}

\input{../front.tex}

%  03.11.2016, 23:55, as PDF to beat.stettler@ins.hsr.ch. 

% Describe how Qemu KVM and Docker work (technical explanation). Also make sure you highlight the 
% differences, pro’s and con’s. 

% Setup and configuration of the Qemu-KVM environment (with explanations) 

% Qemu network configuration 

% A short manual of how to get the ELK stack up and running in Docker 

% Docker network configuration 

% Docker Compose file for the ELK stack 

% Qemu-KVM and Docker networking configuration files/scripts 
\section{KVM / QEMU}
\subsection{Grundlegendes}
KVM ist eine Virtualisierungslösung für Linux, die Gebrauch von Virtualisierungstechniken aktueller Prozessorarchitekturen macht. Um KVM nutzen zu können, muss der Prozessor des Hostsystems Hardwarevirtualisierung unterstützen (was bei den meisten neueren Intel und AMD Prozessoren der Fall ist). KVM an sich stellt die direkte Schnittstelle zum Linux-Kernel zur Verfügung, als Virtualisierungsumgebung kommt QEMU zum Einsatz.

\subsubsection{Terminologie}
\begin{description}
	\item[Host System] \hfill \\
	Beherbergt eine Virtualisierungslösung und stellt Funktionen zur Verfügung damit ein Gastsystem laufen kann.
	\item[Guest System] \hfill \\
	Läuft virtuell innerhalb des Host Systems. Befehle werden durch eine Virtualisierungslösung an die Hardware des Hosts weitergeleitet.
\end{description}

\subsubsection{QEMU}
QEMU ist ein Open Source System-Emulator. QEMU kommuniziert direkt via KVM mit dem Kernel und der CPU, um so das Gastsystem möglichst nahe an der Hardware laufen zu lassen. Eine komplette Emulation (Vollvirtualisierung) ist mit QEMU ebenfalls möglich, führt jedoch zu grossen Performanceeinbussen.

\subsubsection{Libvirt}

Libvirt ist eine Umgebung, welche den Betrieb einer virtuellen Umgebung über eine einheitliche API zur Verfügung stellt. Dies für KVM/QEMU aber auch alternative Umgebungen wie XEN.

Unter dem Überbegriff \emph{Libvirt} werden normalerweise folgende Komponenten verstanden:

\begin{description}
	\item[libvirt] \hfill \\
	\lstinline|libvirt| ist die eigentliche Programmbibliothek, welche die funktionen der Virtualisierungslösung abstrahiert.
	\item[libvirtd] \hfill \\
	\lstinline|libvirtd| ist ein Daemon, welcher den Betrieb der virtuellen Umgebung (Maschinen, Netzwerken, Speicherpools etc.) organisiert und verwaltet.
	\item[virsh] \hfill \\
	\lstinline|virsh| ist ein Verwaltungswerkzeug, über welches die \lstinline|libvirt(d)|-Umgebung konfiguriert und kontrolliert werden kann. Mit \lstinline|virsh start VM1| kann z.B. eine virtuelle Maschine gestartet werden.
\end{description}

\subsubsection{Virt-Manager}

Das Programm \lstinline|virt-manager| ist ein grafisches Verwaltungsprogramm, über welches die von Libvirt abstrahierte virtuelle Umgebung gesteuert werden kann. Die Oberfläche wird von RedHat in Python/GTK entwickelt und erinnert z.B. an die klassische Oberfläche von VMWare\textregistered vSphere\texttrademark.

Der Virt-Manager kann sich (wie auch \lstinline|virsh|) über eine Netzwerkverbindung mit einer (headless) Libvirt-Umgebung in Verbindung setzen (d.h., es sind keine grafischen Komponenten auf Serverseite nötig.)

\subsection{Setup}
\subsubsection{Installation}
\paragraph{Hardwarevirtualisierung vmx/svm} \hfill \\
Damit KVM genutzt werden kann, muss die CPU Hardwarevirtualisierung unterstützen. Dies kann bei neueren Prozessoren im UEFI/BIOS aktiviert werden. Ob die Unterstützung momentan aktiv ist, kann mit folgendem Befehl ermittelt werden\footnote{Achtung: Unter gewissen neue Intel CPUs ist dieser Test aufgrund eines Bugs scheinbar erfolgreich, obwohl die Option noch abgestellt ist. In diesem Fall muss die Option trotzdem noch eingeschaltet werden.}:
\begin{lstlisting}[language=bash]
# Eintrag VMX oder SVM sollten zurueckgegeben werden
egrep '(vmx|svm)' /proc/cpuinfo
\end{lstlisting}


Die nötigen \lstinline|kvm|-Kernelmodule werden unter Fedora bei einem Reboot automatisch geladen. Sollte dies nicht der Fall sein, können sie mit folgendem Befehl geladen werden:
\begin{lstlisting}[language=bash]
lsmod | grep kvm # Sollte kvm ausgeben, falls geladen.

# Ansonsten: Kernel Module manuell laden
sudo modprobe kvm
\end{lstlisting}

Bei selber kompilierten Linux Kerneln können mit \lstinline|make kvmconfig| die entsprechenden Optionen aktiviert werden.

\paragraph{Installation KVM} \hfill \\
Die meisten Linux-Distributionen stellen in den Paket-Repositories KVM, QEMU und Libvirt bereit. Wir verwenden in unseren Beispiel die Linux Distribution \lstinline|Fedora Workstation 24|

\begin{enumerate}
	\item Installation von KVM, QEMU, Libvirt (von Fedora bereitgestelltes Metapaket)\\ \hfill
		\lstinline|sudo dnf install @virtualization libvirt-docs|
	\item Starten des \lstinline|libvirtd|-Dienstes\\ \hfill
		\lstinline|sudo service libvirtd start|
\end{enumerate}

\paragraph{Benutzerzugriff} \hfill \\
Der Benutzer, welcher die Virtuellen Maschinen verwalten soll, muss den Gruppen \lstinline|libvirt| und \lstinline|kvm| hinzugefügt werden (gem. Umgebung von \lstinline|Fedora Workstation 24|)
\begin{lstlisting}[language=bash]
sudo usermod -aG libvirt, kvm $USER
\end{lstlisting}

\subsection{Erstellen der virtuellen Maschinen}

\subsubsection{Festplattenimage vorbereiten}
Festplatten-Images können entweder mit dem Tool \lstinline|qemu-img| erstellt werden. In unserem Fall bauen wir aber auf eine bestehendes Festplatten-Image der Mini-Distribution ''CirrOS'' auf.

\paragraph{Unterstützte Festplattenformate} \hfill \\
QEMU unterstützt als Festplatten Images diverse Formate (die nachfolgende Liste wurde übernommen von \url{https://en.wikibooks.org/wiki/QEMU/Images#Image_types}, Lizenz CC-SA):

\begin{description}
	\item[raw] \hfill \\
		(default) the raw format is a plain binary image of the disc image, and is very portable. On filesystems that support sparse files, images in this format only use the space actually used by the data recorded in them.
	\item[cloop] \hfill \\
		Compressed Loop format, mainly used for reading Knoppix and similar live CD image formats
	\item[cow] \hfill \\
		copy-on-write format, supported for historical reasons only and not available to QEMU on Windows
	\item[qcow] \hfill \\
		the old QEMU copy-on-write format, supported for historical reasons and superseded by qcow2
	\item[qcow2] \hfill \\
		QEMU copy-on-write format with a range of special features, including the ability to take multiple snapshots, smaller images on filesystems that don't support sparse files, optional AES encryption, and optional zlib compression
	\item[vmdk] \hfill \\
		VMware 3 \& 4, or 6 image format, for exchanging images with that product
	\item[vdi] \hfill \\
		VirtualBox 1.1 compatible image format, for exchanging images with VirtualBox.
	\item[vhdx] \hfill \\
		Hyper-V compatible image format, for exchanging images with Hyper-V 2012 or later.
	\item[vpc] \hfill \\
		Hyper-V legacy image format, for exchanging images with Virtual PC / Virtual Server / Hyper-V 2008. 
\end{description}

\paragraph{Anlegen eines neuen Images} \hfill \\
%TODO

\paragraph{Ablegen eines bestehenden virtuellen Images} \hfill \\
%TODO

In unserem Beispiel greifen wir auf ein bestehendes Festplatten-Image der Mini-Distribution ''CirrOS'' aus dem OpenStack-Projekt zurück.

Zur Inbetriebnahme laden wir das Image im \lstinline|qcow2|-Format aus dem Internet und speichern es im Ordner des Standard-Storage-Volume von Libvirt unter Fedora, \lstinline|/var/lib/libvirt/images/|:

\begin{lstlisting}[language=bash]
sudo wget -O /var/lib/libvirt/images/vm1.qcow2 \
	http://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img
\end{lstlisting}

\paragraph{Libvirt Storage Pools} \hfill \\
%TODO



\subsubsection{Virt-Install}
Um eine neue virtuelle Maschine anzulegen, muss eine XML-Datei unter \lstinline|/etc/libvirt/qemu| erstellt werden. Die Datei beschreibt wie die VM auszusehen hat.


\begin{lstlisting}[language=bash]
virsh create /etc/libvirt/qemu/VM1.xml

virsh start VM1 

virsh console VM1
\end{lstlisting}

\begin{lstlisting}[language=XML]
 TODO copy xml vm1, vm2, vm3 from /etc/libvirt/qemu
\end{lstlisting}


\subsubsection{Virt-Clone}
Die weiteren WM's wurden geklont und gemäss Ihren Anforderungen angepasst.
\begin{lstlisting}[language=bash]

\end{lstlisting}


\subsection{Network Configuration}
% TODO Remove sources
% http://wiki.qemu.org/Documentation/Networking#Network_backend_types
% http://wiki.libvirt.org/page/Networking#Debian.2FUbuntu_Bridging


\subsubsection{Grundlegend}
Für jedes virtuelle Netzwerk legt libvirt eine virtuelle Bridge an. Diese können auf dem Host mit \lstinline|brctl show| angezeigt werden. Zudem wird ein virtuelles Interface im zugewiesenen Adressraum (default: 192.168.122.0/24) erstellt, das per NAT mit der physischen Netzwerkkarte verbunden ist. Damit jeder virtuelle Maschine eine gültige IP Adresse kriegt, wird auf dem Host Interface ein DHCP Server (dnsmasq) eingerichtet. Mit dieser Konfiguration kann jede virtuelle Maschine ins Internet, hat jedoch keine Konnektivität zu den anderen VM's. 

\begin{description}
	\item[/var/lib/libvirt/dnsmasq] Die DHCP Konfigurations-Files 
	\item[/etc/libvirt/qemu/networks] Netzwerk Konfigurations-Files
\end{description}




\subsubsection{Host einrichten}
\begin{lstlisting}[language=bash]
virsh net-define /usr/share/libvirt/networks/default.xml
virsh net-autostart default
virsh net-start default
virsh net-edit <network-name>
\end{lstlisting}


\lstinline|/etc/libvirt/qemu/networks|

\subsubsection{Bridge Erstellen}
\begin{lstlisting}[language=xml]
<network>
	<name>VM1_VM2</name>
	<uuid>b7aca73a-21b9-43af-8c91-0af4f95bd29b</uuid>
	<bridge name='virbr1' stp='on' delay='0'/>
	<mac address='52:54:00:1e:b6:ae'/>
	<domain name='VM1_VM2'/>
	<ip address='192.168.100.1' netmask='255.255.255.0'>
	<dhcp>
	<range start='192.168.100.128' end='192.168.100.254'/>
	</dhcp>
	</ip>
</network>
\end{lstlisting}

\subsection{KVM / QEMU ohne Libvirt}
%TODO.



\section{Docker}
\subsection{Grundlegendes}
Docker ist im Gegensatz zu KVM keine Lösung für virtuelle Maschinen (und damit unabhängige Betriebssysteme mit eigenem CPU-Scheduling etc.) sondern basiert auf Linux Container (LXC). Ein LXC ist eine vom Kernel bereitgestellte virtuelle Umgebung zur isolierten Ausführung von Prozessen.

Docker ermöglicht neben der Steuerung von isolierten Applikationsausführung in LXC die Konfiguration von Netzwerkeinstellungen bzw. Portfreigabe ein komplett isoliertes Dateisystem pro Applikation (sogenannte Images). Damit ist es möglich, Systemunabhängig immer die gleiche Plattform zur Ausführung zu paketieren und weiter zu verteilen. Von Docker erstellte Images werden üblicherweise mit einem Dateisystem erstellt, welches Snapshots erlaubt (z.B. AUFS, UnionFS oder BTRFS).

Zur Erstellung von eigenen Images, auf deren Basis eine Applikation ausgeführt wird, können mit einem \lstinline[]|Dockerfile| komplette ''Bauanleitungen'' erstellt werden. Im \lstinline[]|Dockerfile| sind die Eigenschaften des neuen Container und Images sowie darauf auszuführende Kommandos zur Bereitstellung der Umgebung hinterlegt.

So gebaute Images (oft in diesem Zusammenhang auch einfach als Container bezeichnet) können über eine Online-Plattform verteilt werden. Die Firma Docker Inc. stellt zu diesem Zweck die öffentliche Plattform \emph{DockerHub} unter \url{https://hub.docker.com/} zur Verfügung.

Beim Bauen eines Containers wird üblicherweise auf die Basis eines bestehenden Containers auf der DockerHub-Plattform zurückgegriffen. So gibt es dort zum Beispiel Images, welche die Dateisystemstruktur und Bibliotheken eines minimalen Ubuntu-Systems oder sogar einer Umgebung für  wie Ruby on Rails zur Verfügung stellen.


\subsubsection{Terminologie}
\begin{description}
	\item[Container, VDI: Virtual Disk Image] \hfill \\
	Virtuelle Festplatte des Gastsystems. Es gibt statische und dynamische Container.
	%TODO: Unter Container wird z.T. auch die Konfiguration einbezogen.
\end{description}


\subsubsection{Docker Compose}

Docker Compose ist ein ergänzendes Programm zu Docker, welches die Provisionierung und Verknüpfung von mehreren Docker-Containern erlaubt. Der Aufbau/Start der Container wird mittels dem Kommando \lstinline|docker-compose| gesteuert; dies liest die \lstinline|docker-compose.yml|-Datei ein, in welcher weitergehende die Anweisungen für die Konfiguration der Container definiert sind.
%TODO Michi: Fehlt hier noch etwas?

\subsubsection{Docker Swarm}
Docker Swarm ist ein Orchestrierungs-Werkzeug für den Betrieb von Docker-Clustern (oder auch einzelnen Docker Hosts).
%TODO Michi: Was kann das noch mehr?.



\subsection{Docker IO}
\begin{lstlisting}[language=bash]
# docker container suchen
docker sarch <package-name>

# docker container herunterladen
docker pull <package-name>

# Image veroeffentlichen
docker push <image name>

# docker container starten
docker run <package-name> <app to execute>

# Aktuell ausgefuerten Container anzeigen
docker ps

# Liste alle lokal vorliegenden Images
docker images

# Image entfernen
docker rmi <image>

# Container entfernen
docker rm <container>
\end{lstlisting}


\subsection{Beschreibung}
\paragraph{Vorteile}
\begin{itemize}
	\item Äusserts sparsamer Umgang mit Ressourcen und eine kurze Startzeit	
	\item Mit Hilfe von Vagrant äusserts einfach einen Docker Container zu installieren
	\item Austausch von Images fällt durch den Gebrauch von öffentlichen Registries leicht.
\end{itemize}
\paragraph{Nachteile}
\begin{itemize}
	\item Da die Container auf den Linux Kernel zugreifen, ist es nicht möglich Windows Anwendungen in einem Docker Container auszuführen.
	\item Einschränkung auf 64Bit basiertes Linux oder Mac OSX (%TODO immer noch=? -> Meines Wissens schon!
\end{itemize}

\subsection{ELK Stack Setup (Elasticseach, Logstash, Kibana)}
\subsubsection{Vorraussetzungen}
\paragraph{SELinux} \hfill \\
Da wir mit einem Fedora arbeiten, müssen vorgän
\begin{lstlisting}[language=bash]
chcon -R system_u:object_r:admin_home_t:s0 docker-elk
\end{lstlisting}



\subsection{Network Configuration}

\subsection{Docker Compose File ELK Stack}




\section{Vergleich der Technologien}



\subsection{KVM} %TODO
\paragraph{Vorteile}
\begin{itemize}
	\item Ein Vorteil von KVM ist, dass die Gastsysteme fast mit nativer Geschwindigkeit laufen, d.h. das Gastsystem reagiert nahezu so schnell wie ein natives System. 
\end{itemize}
\paragraph{Nachteile}
\begin{itemize}
	\item Hoher Bedarf an Festplatten und Arbeitsspeicher und langwieriger Ladevorgang beim Starten der virtuellen Maschienen
\end{itemize}

\input{appendix.tex}
