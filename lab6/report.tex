\input{../template.tex}

% Dokumentinformationen
\newcommand{\SUBJECT}{Report}
\newcommand{\TITLE}{Cloud Infrastructre Lab 6}

\input{../front.tex}

\section{Modern Data Center Requirements}

Die Ansprüche an eine Data Center hat sich in den letzten zehn Jahren stark gewandelt. In den folgenden Abschnitten werfen wir einen Blick auf die Änderungen der letzten Jahre sowie der neu entstandenen Ansprüche an Data Centers.

% - was ändert sich
% - was ist heutigen DC anders als 20 jahre

\subsection{Network architecture}\label{sec:network-architecture}
\subsubsection{Vor ca. 2008}
Vor ca. 2008 waren Data Center üblicherweise in ''Silos'' aufgeteilt: Jede Abteilung und Applikation hatte meist ein eigenes ''Rack'' mit physischen Servern. Damit war die Struktur eher starr und teuer; Skalierung von Ressourcen war nur mit physischem erweitern der Infrastruktur möglich.

\paragraph{Das Netzwerk} war entsprechend aufgebaut; Subnetze wurden statisch Abteilungen und Applikationen zugewiesen. Dies war möglich, da die Infrastruktur keinen kurzfristigen, grossen Anpassungen erlaubte.

\subsubsection{Seit ca. 2008}
Seit ca. 2008 hält die Virtualisierung in das Data Center Einzug. Damit wird die Umgebung nicht mehr in ''Silos'' aufgeteilt, sondern in ressourcen-Pools für Computation, Storage und Netzwerkvirtualisierung. Das verknüpfen dieser Pools wird durch den Betrieb von virtuellen Servern möglich. Die wesentlichen Vorteile dieser Umgebung lassen sich kurz zusammenfassen auf die...
\begin{itemize}
	\item Reduktion der Komplexität
	\item Vereinfachung des Betriebs
	\item Erhöhung der Auslastungseffizienz (Bündelungsgewinn)
	\item Erhöhte Ausfallssicherheit
	\item Einfachere Skalierung der Infrastruktur
	\item Ermöglichung von Automatisierung
\end{itemize}

Seit 2010 bis heute wird neben der Virtualisierung die Automatisierung von möglichst vielen Komponenten vorangetrieben. Damit wird es möglich, mit weniger personellem Aufwand mehr Server zu betreiben und repetitive Aufgaben autonom (oder teilautonom) erledigen zu lassen.

\paragraph{Das Netzwerk} muss dadurch ebenfalls flexibler und einfacher änderbar sein. Dies wird entweder durch eine ''flachere'' Netzwerkstruktur, oder dem Einsatz von Fabrics erreicht. Allerdings ist der klassische Netzwerkstack nicht für solche Strukturen Designed; hier kommen Protokolle wie TRILL und VXLAN sowie die Virtualisierung von Netzwerkkomponenten ins Spiel.

Weitere Änderungen im Bezug auf den Netzwerkverkehr sind: 
\begin{itemize}
	\item Eine deutlich höhere Auslastung des East-West-Verkehrs: Der Verkehr bleibt eher im Data Center, verursacht wird er z.B. durch das Verschieben von VMs\footnote{Virtuelle Maschinen; siehe Lab 5 für alle Details.}. \hfill \\
		 Pre-2008 gab es in erster Linie Netzverkehr zwischen Clients und Servern.
	\item Sogenannte ''Elephant Flows'' dominieren den Verkehr im Netzwerk (Speicher, Verteilte Datenbanken etc.)
	\item Mehr (kleine) Auslastungsspitzen im Netzwerk; dies kann zu Paketverlust führen.
	\item Betrieb von ''map-reduce'' applikationen, welche viel eingehenden TCP-Netzverkehr haben (many-to-one traffic)
\end{itemize}


\subsection{Challanges}

Durch die in Kapitel \ref{sec:network-architecture} genannten Änderungen in der Netzwerkarchitektur ergeben sich einige neue Challanges:
\begin{itemize}
	\item Es muss viel mehr Netzverkehr East-West fliessen können
	\item Aufgrund der neuen Applikationsarchitekturen und Datengrössen gibt es überhaupt mehr Netzwerkverkehr.
	\item IP-Netze müssen sich über mehrere Nodes (physische und virtuelle Server) erstrecken können
	\item Die Netzwerk-Struktur muss schnell und einfach geändert werden können
	\item Es müssen höhere Lastspitzen abgefangen werden können
\end{itemize}

Einige weitere neuartige Requirements sind auch im nächsten Kapitel~\ref{sec:requirements-an-das-netzwerk} aufgelistet.

\subsection{Requirements an das Netzwerk}\label{sec:requirements-an-das-netzwerk}
Es gibt somit einige neue grundlegende Anforderungen an das Netzwerk\footnote{Weitgehend übernommen aus der Modulvorlesung \lstinline|09_Changes in the Datacenter Network Design.pdf| von Prof. B. Stettler.}.
\subsubsection{Eigenschaften Forwarding}
\begin{itemize}
	\item Höhere Geschwindigkeiten (z.B. 10Gbps im Access Layer, 40/100Gbps im Core Layer)
	\item Verstärktes Multipath für L3 und evtl. L2 Traffic, um den East-West Durchsatz zu erhöhen. (Kein Porl/Link Blocking wie bei STP)
	\item Weniger Netzwerkhops (zur Senkung der Latenzzeiten)
	\item Optimales L3 Forwarding
	\item Trennung von L3 verkehr (L3 Path Isolation)
	\item IPv6
	\item Speicher- und Netzwerk sind mit mindestens 10GE verbunden (iSCSI oder FCoE)
	\item Verlustfreier Netzwerkverkehr (für DCB)
\end{itemize}

\subsubsection{Control \& Management Funktionen}
\begin{itemize}
	\item Enge Verzahnung des Netzwerks mit den virtuellen Servern
	\item L2 ohne STP (und ähnliche Protokolle, aufgrund Port-Blocking)
	\item Effizientes Management
	\item Einfache Provisionierung / Erweiterung des Netzwerks
\end{itemize}


\subsubsection{Skalierbarkeit}
\begin{itemize}
	\item Hohe Anzahl von VLANs
	\item Grosse Tabellengrössen (MAC, ARP, L3, IPMC etc.)
	\item Schnelles Netz (per Design, auch bei grossen Netzvergrösserungen)
\end{itemize}

\subsubsection{Weitere Anforderungen }
\begin{itemize}
	\item Rechtliche Compliance (Datenschutz/Datensicherheit)
	\item Multitenancy (Abtrennung von mehreren Kunden im selben Netz)
\end{itemize}


\section{TRILL}

\subsection{Theorie}
\subsection{Terminologie}
\begin{description}
	\item[RBrige] Bridge die TRILL unterstützt und verwendent
	\item[Ingress RBRige] \hfill \\
	Bridges die beim Eingang in die TRILL ''Wolke'' stehen. Sie fügen den TRILL Header hinzu
	\item[Egress RBRige] \hfill \\
	Bridges die beim Ausgang der TRILL ''Wolke'' stehen. Sie entfernen den TRILL Header.
	\item[Transit RBridge]  \hfill \\
	Bridges die den TRILL Verkehr nur weiterleiten und dabei nur den Outer Ethernet Header beachten. Sie stehen innerhalb der TRILL ''Wolke''.
\end{description}

\subsubsection{Funktion} %function / protocol header
Das TRILL Protokoll  (Transparent Interconnection of Lots of Links) implementiert ein Routing auf Layer 2. Das Routing wird mit sogenannten RBridges vollzogen. RBridges routen die verpackten Ethernet Frames mit dem Link-State-Protokoll IS-IS (Intermediate System to Intermediate System). TRILL kann relativ einfach in eine bestehendes Netz eingefügt werden, da Bridges ohne TRILL Funktion, die restlichen RBridges als Wolke und somit als ein grossen Switch wahrnehmen. (Vergleichbar mit MPLS). \\ 

Versendet ein Client A ein Paket an Client B, wird das MAC Frame bei der Ingress RBrige in ein TRILL Paket verpackt. Anschliessend routet IS-IS das Paket zur Egress Bridge welche den TRILL Header wieder entfernt und das ursprüngliche MAC Frame auspackt.  \\

%TODO Check ECMP
Edge RBridges (Ingress, Egress) lernen die angeschlossen Clients auf die klassische Art und Weise über ARP. Die gelernenten MAC-Adressen werden dann über IS-IS an die weiteren RBridges verteilt. Da Link State Protokolle über die gesammte Netzwerktopologie bescheid wissen, kann IS-IS optimale Pfade für Unicast, sowie Distribution Trees für unbekannte Hosts und Broadcast und Multicast Gruppen berechnen. Die berechneten Bäume bilden einen Pfad zu allen Egress Bridges ab. Durch das Equal Cost Multipath Routing (ECMP) werden alle Pfade mit gleichen Kosten zu einem Ziel parallel genutzt. Dadurch erreicht man eine höhere Bandbreit, als dies unter STP möglich war. IS-IS setzt zur Berechnung des kürzesten Weges den Dijkstra-Algorithmus ein und verwendet zusätzlich noch einen Hop Count im TRILL Header zum Ausschliessen von Loops.

\subsection{Protokoll Header}
Ein TRILL Frame ist in drei Schichten aufgeteilt:
\begin{description}
	\item[Outer Ethernet Header] \hfill \\
	Der äussere Ethernet Header wird bei jedem Hop geändert. Dabei bleibt der innere Header konsistenz (inkl. VLAN Tag). Im Outer Header stehen die MAC Adressen der RBridges.
	\item[TRILL Header] \hfill \\
	Das interessanteste im TRILL Header ist die Ingress-RBridge (Source) und Egress-RBrige (Destination). Jede RBridge wird mit einem Nickname (2Byte Hexadezimal) eindeutig identifiziert. (z.B \lstinline[]|0x56ce|) 
	\begin{itemize}
		\item Hop Count: Wird beim passieren jeder RBridge verkleinert und verhindert dass ein Paket zu loopen beginnt. Jede RBridge setze die erwartete Anzahl Hops bis ihrem Ziel.
		\item Nickname: Der RBridge Nickname ist eine Abkürzung (2Byte) der 6Byte langen IS-IS System ID der Bridge. Sie ist eindeutig innerhalb eines Netzes. 
		\item M Bit (Multidestination): 0 = Unicast, 1 = Distribution Tree
	\end{itemize}
	\item[Inner Ethernet Header] \hfill \\
	Im Inner Ethernet Header stehen MAC-Adressen der beiden Endstation sowie der VLAN Tag.
\end{description}

\begin{figure}[h]
\centering
\includegraphics[width=0.6\linewidth]{images/trill_header}
\caption{TRILL Frame}
\label{fig:trillheader}
\end{figure}

\subsubsection{Ziel von TRILL} %goal of trill
Das Ziel von TRILL ist es auf Layer 2 ein Routing zu betreiben und dabei die Nachteile von STP zu lösen.

\subsubsection{Warum wurde TRILL entwickelt?} %why was trill developed?
TRILL wurde entwickelt um das Spanning Tree Protocol (STP) zu ersetzen. STP wurde entwickelt um Bridging Loops zu unterbinden. Das Problem bei STP ist, dass es eine relativ grosse Konvergenzzeit hat und Links blockiert, was in Rechenzentren inakzeptabel ist. TRILL wurde entwickelt um genau dieses Problem zu lösen. TRILL verwendet IS-IS (Intermediate System to Intermediate System Protocol) auf Layer 2. IS-IS ist wie OSPF eine Link State Protokoll welches aber im Gegensatz zu OSPF auf L2 operieren kann. Wie alle Link State Protokollen weiss jede RBridge über die gesamte Topologie bescheid. 

\subsubsection{Wo und wie kann TRILL eingesetzt werden (Use Cases)?} %where and how can trill be used? (use cases)


\paragraph{High Performance Datacenter}
Bei Datencenter versucht man die Spine-Leaf Architektur umzusetzen. Dazu integriert man Edge- und Aggregation-Layer und setzt im Core mehrere kleine Systeme statt wenig grosse ein, die man zu einem virtuell Device zusammenfasst. Diese Flachen Netze werden dann mit TRILL verwaltet. Da TRILL alle verfügbaren Ports und Pfade nutzt, kann die Payload mit einer maximalen Bandbreite übertragen werden. 


\subsubsection{Ist TRILL kompatibel mit traditionellen Protokollen?} %is trill comparable to a traditional protcol?
%  if yes, what are the differences and which limitiations does TRILL solve?
TRILL ist kompatibel mit VLAN und STP. Der VLAN Tag des Inner Ethernet Header wird bei der Übertragung durch Transit RBridges nicht beachtet. Der VLAN Tag im Outer Ethernet Header wird nur verwendet wenn zwei RBridges über unterschiedliche VLAN's kommunizieren. STP Bridges ohne TRILL Funktionalität erkennen die TRILL ''Wolke'' als einen grossen Switch. TRILL agiert für das restliche 802.1 Netzwerk als eigenständiges System operiert somit oberhalb des klassischen Layer 2.  
%TODO

\subsubsection{Was sind die Vor- und Nachteile von TRILL?}%what are the advantages and disadvantages of TRILL
\paragraph{Vorteile} \hfill \\
Die Vorteile von TRILL decken sich mit den Kritikpunkten an STP. So gibt es bei TRILL keine blockierten Ports (die ganze Bandbreite kann genutzt werden) und es gibt keine Probleme mit der Konvergationszeit des L2 Netzes. Dadurch kann auf STP verzichtet werden. 
TRILL erlaubt es Virtuelle Maschienen zu verschieben (z.B VMotion) ohne dass man sich Gedanken über die IP Subnetze machen muss.
%TODO ECMP

\paragraph{Nachteile} \hfill \\
Ein Kritikpunkt an TRILL ist, dass es zu schlechtem Design in den Rechenzentren führe und Alternative Protokolle wie z.B SPB das Problem eleganter lösen.

\subsubsection{Gibt es andere moderne Technologien, welche TRILL ähnlich sind?}%are there other modern technologies which are similar to TRILL?
%  if yes, what are the differences between them
Der grösste Konkurenz von TRILL ist SPB (Shortest Path Bridging oder IEEE 802.1aq). SPB wurde als Erweiterung von VLAN entwickelt, mit dem gleichen Ziel, um die Konvergenzzeit von STP zu verbessern. SPB verwendet das herkömmliche Header Format, wodurch ohne Hardware Update in ein bestehendes Netzwerk eingefügt werden kann. 


\subsection{Lab Konfiguration}
\begin{figure}[h]
	\centering
	\includegraphics[width=1\linewidth]{trill_network_layer2}
	\caption{Lab TRILL Layer 1/2 Struktur (Quelle: Auftrag Lab 7)}
	\label{fig:trillnetworklayer2}
\end{figure}
%TODO: Welcher switch welche funktion.

\subsubsection{Aufzeichnung Traffic etc}

Wir haben eine Wireshark

%TODO: Screenshots Wireshark mit erkenntnissen / erklährungen

\subsubsection{Trees}

%-> Tree Struktur Vor Einstecken 
%-> Nach Einstecken eines Clients auf einem Swtich
%-> Nach "Zügeln" von Client auf den anderen Access Switch
%(-> Wieder zurückstecken auf den alten Switch)
%TODO: Grafik erstellen
%TODO: Erklären wie zusande gekommen

%:: Der Tiefste Nickname ist der Multicast-root

\subsubsection{PacketFlow}
%-> Normaler Unicast Weg
%-> Broadcast wege
%-> Multicast
%TODO: Erklären, wie der Fluss bei Broadcast, Multicast und Unicast aussieht

\subsubsection{Mac Learning}

%TODO
%-> Was passiert nach Client einstecken (IS-IS)
%-> Was passiert nach wechseln Client auf anderen Access Switch


\section{VXLAN}
\subsection{Terminologie}
\begin{description}
	\item[VXLAN: Virtual eXtensible Local Area Network] description
	\item[VNI: VXLAN Network Identifier] 
	\item[VTEP: VXLAN Tunnel End Point] description 

\end{description}
%TODO
\input{appendix.tex}
